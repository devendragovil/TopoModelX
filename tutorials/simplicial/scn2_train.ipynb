{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Simplex Convolutional Network (SCN) of Rank 2\n",
    "\n",
    "This notebook illustrates the SCN layer proposed in [Yang22c]_ for a simplicial complex of\n",
    "rank 2, that is for 0-cells (nodes), 1-cells (edges) and 2-cells (faces) only.\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [YSB22] Ruochen Yang, Frederic Sala, and Paul Bogdan.\n",
    "    Efficient Representation Learning for Higher-Order Data with \n",
    "    Simplicial Complexes. In Bastian Rieck and Razvan Pascanu, editors, \n",
    "    Proceedings of the First Learning on Graphs Conference, volume 198 \n",
    "    of Proceedings of Machine Learning Research, pages 13:1–13:21. PMLR, \n",
    "    09–12 Dec 2022a. https://proceedings.mlr.press/v198/yang22a.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import toponetx.datasets as datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from topomodelx.nn.simplicial.scn2_layer import SCN2Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import dataset ##\n",
    "\n",
    "According to the original paper, SCN is good at simplex classification. Thus, I chose shrec_16, a benchmark dataset for 3D mesh classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shrec 16 small dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "ys = ys.reshape((100, 1))\n",
    "simplexes = shrec[\"complexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th simplicial complex has 252 nodes with features of dimension 6.\n",
      "The 6th simplicial complex has 750 edges with features of dimension 10.\n",
      "The 6th simplicial complex has 500 faces with features of dimension 7.\n"
     ]
    }
   ],
   "source": [
    "i_complex = 6\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_0s[i_complex].shape[0]} nodes with features of dimension {x_0s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_1s[i_complex].shape[0]} edges with features of dimension {x_1s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_2s[i_complex].shape[0]} faces with features of dimension {x_2s[i_complex].shape[1]}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on the domain. In this case, we need the normalized Laplacian matrix on nodes, edges, and faces. We also convert the neighborhood structures to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_0s = []\n",
    "laplacian_1s = []\n",
    "laplacian_2s = []\n",
    "for x in simplexes:\n",
    "    laplacian_0 = x.normalized_laplacian_matrix(rank=0)\n",
    "    laplacian_1 = x.normalized_laplacian_matrix(rank=1)\n",
    "    laplacian_2 = x.normalized_laplacian_matrix(rank=2)\n",
    "\n",
    "    laplacian_0 = torch.from_numpy(laplacian_0.todense()).to_sparse()\n",
    "    laplacian_1 = torch.from_numpy(laplacian_1.todense()).to_sparse()\n",
    "    laplacian_2 = torch.from_numpy(laplacian_2.todense()).to_sparse()\n",
    "\n",
    "    laplacian_0s.append(laplacian_0)\n",
    "    laplacian_1s.append(laplacian_1)\n",
    "    laplacian_2s.append(laplacian_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCN2(torch.nn.Module):\n",
    "    \"\"\"Simplex Convolutional Network Implementation for binary node classification.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_channels_0 : int\n",
    "        Dimension of input features on nodes.\n",
    "    in_channels_1 : int\n",
    "        Dimension of input features on edges.\n",
    "    in_channels_2 : int\n",
    "        Dimension of input features on faces.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Amount of message passing layers.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, in_channels_0, in_channels_1, in_channels_2, num_classes, n_layers=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                SCN2Layer(\n",
    "                    in_channels_0=in_channels_0,\n",
    "                    in_channels_1=in_channels_1,\n",
    "                    in_channels_2=in_channels_2,\n",
    "                )\n",
    "            )\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.lin_0 = torch.nn.Linear(in_channels_0, num_classes)\n",
    "        self.lin_1 = torch.nn.Linear(in_channels_1, num_classes)\n",
    "        self.lin_2 = torch.nn.Linear(in_channels_2, num_classes)\n",
    "\n",
    "    def forward(self, x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2):\n",
    "        \"\"\"Forward computation.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        x_0 : tensor\n",
    "            shape = [n_nodes, channels]\n",
    "            Node features.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        _ : tensor\n",
    "            shape = [n_nodes, 2]\n",
    "            One-hot labels assigned to nodes.\n",
    "\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2)\n",
    "        x_0 = self.lin_0(x_0)\n",
    "        x_1 = self.lin_1(x_1)\n",
    "        x_2 = self.lin_2(x_2)\n",
    "\n",
    "        # Take the average of the 2D, 1D, and 0D cell features. If they are NaN, convert them to 0.\n",
    "        two_dimensional_cells_mean = torch.nanmean(x_2, dim=0)\n",
    "        two_dimensional_cells_mean[torch.isnan(two_dimensional_cells_mean)] = 0\n",
    "        one_dimensional_cells_mean = torch.nanmean(x_1, dim=0)\n",
    "        one_dimensional_cells_mean[torch.isnan(one_dimensional_cells_mean)] = 0\n",
    "        zero_dimensional_cells_mean = torch.nanmean(x_0, dim=0)\n",
    "        zero_dimensional_cells_mean[torch.isnan(zero_dimensional_cells_mean)] = 0\n",
    "        # Return the sum of the averages\n",
    "        return (\n",
    "            two_dimensional_cells_mean\n",
    "            + one_dimensional_cells_mean\n",
    "            + zero_dimensional_cells_mean\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model with our pre-made neighborhood structures and specify an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels_0 = x_0s[i_complex].shape[1]\n",
    "in_channels_1 = x_1s[i_complex].shape[1]\n",
    "in_channels_2 = x_2s[i_complex].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SCN2(in_channels_0, in_channels_1, in_channels_2, num_classes=1)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_0s_train, x_0s_test = train_test_split(x_0s, test_size=test_size, shuffle=False)\n",
    "x_1s_train, x_1s_test = train_test_split(x_1s, test_size=test_size, shuffle=False)\n",
    "x_2s_train, x_2s_test = train_test_split(x_2s, test_size=test_size, shuffle=False)\n",
    "\n",
    "laplacian_0s_train, laplacian_0s_test = train_test_split(\n",
    "    laplacian_0s, test_size=test_size, shuffle=False\n",
    ")\n",
    "laplacian_1s_train, laplacian_1s_test = train_test_split(\n",
    "    laplacian_1s, test_size=test_size, shuffle=False\n",
    ")\n",
    "laplacian_2s_train, laplacian_2s_test = train_test_split(\n",
    "    laplacian_2s, test_size=test_size, shuffle=False\n",
    ")\n",
    "\n",
    "y_train, y_test = train_test_split(ys, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for a low number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 307.3329\n",
      "Epoch: 2 loss: 271.0158\n",
      "Test_loss: 489.0029\n",
      "Epoch: 3 loss: 211.3648\n",
      "Epoch: 4 loss: 133.2150\n",
      "Test_loss: 213.6805\n",
      "Epoch: 5 loss: 86.5624\n",
      "Epoch: 6 loss: 78.2548\n",
      "Test_loss: 107.0384\n",
      "Epoch: 7 loss: 77.8108\n",
      "Epoch: 8 loss: 77.7633\n",
      "Test_loss: 100.3024\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 8\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2, y in zip(\n",
    "        x_0s_train,\n",
    "        x_1s_train,\n",
    "        x_2s_train,\n",
    "        laplacian_0s_train,\n",
    "        laplacian_1s_train,\n",
    "        laplacian_2s_train,\n",
    "        y_train,\n",
    "    ):\n",
    "        x_0, x_1, x_2, y = (\n",
    "            torch.tensor(x_0).float().to(device),\n",
    "            torch.tensor(x_1).float().to(device),\n",
    "            torch.tensor(x_2).float().to(device),\n",
    "            torch.tensor(y).float().to(device),\n",
    "        )\n",
    "        laplacian_0, laplacian_1, laplacian_2 = (\n",
    "            laplacian_0.float().to(device),\n",
    "            laplacian_1.float().to(device),\n",
    "            laplacian_2.float().to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2, y in zip(\n",
    "                x_0s_test,\n",
    "                x_1s_test,\n",
    "                x_2s_test,\n",
    "                laplacian_0s_test,\n",
    "                laplacian_1s_test,\n",
    "                laplacian_2s_test,\n",
    "                y_test,\n",
    "            ):\n",
    "                x_0, x_1, x_2, y = (\n",
    "                    torch.tensor(x_0).float().to(device),\n",
    "                    torch.tensor(x_1).float().to(device),\n",
    "                    torch.tensor(x_2).float().to(device),\n",
    "                    torch.tensor(y).float().to(device),\n",
    "                )\n",
    "                laplacian_0, laplacian_1, laplacian_2 = (\n",
    "                    laplacian_0.float().to(device),\n",
    "                    laplacian_1.float().to(device),\n",
    "                    laplacian_2.float().to(device),\n",
    "                )\n",
    "                y_hat = model(x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2)\n",
    "                test_loss = loss_fn(y_hat, y)\n",
    "            print(f\"Test_loss: {test_loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
