{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Simplex Convolutional Network (SCN) of Rank 2\n",
    "\n",
    "This notebook illustrates the SCN layer proposed in [Yang22c]_ for a simplicial complex of\n",
    "rank 2, that is for 0-cells (nodes), 1-cells (edges) and 2-cells (faces) only.\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [YSB22] Ruochen Yang, Frederic Sala, and Paul Bogdan.\n",
    "    Efficient Representation Learning for Higher-Order Data with \n",
    "    Simplicial Complexes. In Bastian Rieck and Razvan Pascanu, editors, \n",
    "    Proceedings of the First Learning on Graphs Conference, volume 198 \n",
    "    of Proceedings of Machine Learning Research, pages 13:1–13:21. PMLR, \n",
    "    09–12 Dec 2022a. https://proceedings.mlr.press/v198/yang22a.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import toponetx.datasets as datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from topomodelx.nn.simplicial.scn2 import SCN2\n",
    "from topomodelx.utils.sparse import from_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import dataset ##\n",
    "\n",
    "According to the original paper, SCN is good at simplex classification. Thus, I chose shrec_16, a benchmark dataset for 3D mesh classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shrec 16 small dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "ys = ys.reshape((100, 1))\n",
    "simplexes = shrec[\"complexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th simplicial complex has 252 nodes with features of dimension 6.\n",
      "The 6th simplicial complex has 750 edges with features of dimension 10.\n",
      "The 6th simplicial complex has 500 faces with features of dimension 7.\n"
     ]
    }
   ],
   "source": [
    "i_complex = 6\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_0s[i_complex].shape[0]} nodes with features of dimension {x_0s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_1s[i_complex].shape[0]} edges with features of dimension {x_1s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_2s[i_complex].shape[0]} faces with features of dimension {x_2s[i_complex].shape[1]}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on the domain. In this case, we need the normalized Laplacian matrix on nodes, edges, and faces. We also convert the neighborhood structures to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_0s = []\n",
    "laplacian_1s = []\n",
    "laplacian_2s = []\n",
    "for x in simplexes:\n",
    "    laplacian_0 = x.normalized_laplacian_matrix(rank=0)\n",
    "    laplacian_1 = x.normalized_laplacian_matrix(rank=1)\n",
    "    laplacian_2 = x.normalized_laplacian_matrix(rank=2)\n",
    "\n",
    "    laplacian_0 = from_sparse(laplacian_0)\n",
    "    laplacian_1 = from_sparse(laplacian_1)\n",
    "    laplacian_2 = from_sparse(laplacian_2)\n",
    "\n",
    "    laplacian_0s.append(laplacian_0)\n",
    "    laplacian_1s.append(laplacian_1)\n",
    "    laplacian_2s.append(laplacian_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model with our pre-made neighborhood structures and specify an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels_0 = x_0s[i_complex].shape[1]\n",
    "in_channels_1 = x_1s[i_complex].shape[1]\n",
    "in_channels_2 = x_2s[i_complex].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SCN2(in_channels_0, in_channels_1, in_channels_2, num_classes=1)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_0s_train, x_0s_test = train_test_split(x_0s, test_size=test_size, shuffle=False)\n",
    "x_1s_train, x_1s_test = train_test_split(x_1s, test_size=test_size, shuffle=False)\n",
    "x_2s_train, x_2s_test = train_test_split(x_2s, test_size=test_size, shuffle=False)\n",
    "\n",
    "laplacian_0s_train, laplacian_0s_test = train_test_split(\n",
    "    laplacian_0s, test_size=test_size, shuffle=False\n",
    ")\n",
    "laplacian_1s_train, laplacian_1s_test = train_test_split(\n",
    "    laplacian_1s, test_size=test_size, shuffle=False\n",
    ")\n",
    "laplacian_2s_train, laplacian_2s_test = train_test_split(\n",
    "    laplacian_2s, test_size=test_size, shuffle=False\n",
    ")\n",
    "\n",
    "y_train, y_test = train_test_split(ys, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for a low number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 101.5365\n",
      "Epoch: 2 loss: 86.1983\n",
      "Epoch: 3 loss: 81.8696\n",
      "Epoch: 4 loss: 81.8369\n",
      "Epoch: 5 loss: 78.9703\n",
      "Epoch: 6 loss: 80.3754\n",
      "Epoch: 7 loss: 80.0700\n",
      "Epoch: 8 loss: 78.9223\n",
      "Epoch: 9 loss: 78.0657\n",
      "Epoch: 10 loss: 77.6546\n",
      "Test_loss: 25.7606\n",
      "Epoch: 11 loss: 77.2089\n",
      "Epoch: 12 loss: 76.7527\n",
      "Epoch: 13 loss: 76.6223\n",
      "Epoch: 14 loss: 76.8686\n",
      "Epoch: 15 loss: 78.1641\n",
      "Epoch: 16 loss: 77.4376\n",
      "Epoch: 17 loss: 76.4670\n",
      "Epoch: 18 loss: 79.9321\n",
      "Epoch: 19 loss: 80.1980\n",
      "Epoch: 20 loss: 76.2536\n",
      "Test_loss: 26.8926\n",
      "Epoch: 21 loss: 76.1279\n",
      "Epoch: 22 loss: 77.9043\n",
      "Epoch: 23 loss: 75.4726\n",
      "Epoch: 24 loss: 74.6772\n",
      "Epoch: 25 loss: 74.3738\n",
      "Epoch: 26 loss: 74.3356\n",
      "Epoch: 27 loss: 75.8778\n",
      "Epoch: 28 loss: 77.8681\n",
      "Epoch: 29 loss: 74.8892\n",
      "Epoch: 30 loss: 74.5119\n",
      "Test_loss: 17.8183\n",
      "Epoch: 31 loss: 76.2832\n",
      "Epoch: 32 loss: 76.1104\n",
      "Epoch: 33 loss: 74.9951\n",
      "Epoch: 34 loss: 76.9677\n",
      "Epoch: 35 loss: 76.1779\n",
      "Epoch: 36 loss: 74.7662\n",
      "Epoch: 37 loss: 73.7156\n",
      "Epoch: 38 loss: 75.7276\n",
      "Epoch: 39 loss: 74.2640\n",
      "Epoch: 40 loss: 72.9013\n",
      "Test_loss: 12.0230\n",
      "Epoch: 41 loss: 75.0649\n",
      "Epoch: 42 loss: 73.1026\n",
      "Epoch: 43 loss: 73.8109\n",
      "Epoch: 44 loss: 81.0943\n",
      "Epoch: 45 loss: 79.1915\n",
      "Epoch: 46 loss: 77.3374\n",
      "Epoch: 47 loss: 76.4350\n",
      "Epoch: 48 loss: 72.1659\n",
      "Epoch: 49 loss: 73.2236\n",
      "Epoch: 50 loss: 74.6358\n",
      "Test_loss: 11.5087\n",
      "Epoch: 51 loss: 72.0251\n",
      "Epoch: 52 loss: 70.9702\n",
      "Epoch: 53 loss: 70.7366\n",
      "Epoch: 54 loss: 71.8592\n",
      "Epoch: 55 loss: 74.9612\n",
      "Epoch: 56 loss: 71.4760\n",
      "Epoch: 57 loss: 70.5336\n",
      "Epoch: 58 loss: 69.8716\n",
      "Epoch: 59 loss: 69.9956\n",
      "Epoch: 60 loss: 70.6182\n",
      "Test_loss: 6.9614\n",
      "Epoch: 61 loss: 72.8307\n",
      "Epoch: 62 loss: 71.5236\n",
      "Epoch: 63 loss: 75.7701\n",
      "Epoch: 64 loss: 73.9068\n",
      "Epoch: 65 loss: 74.2915\n",
      "Epoch: 66 loss: 69.6303\n",
      "Epoch: 67 loss: 70.3693\n",
      "Epoch: 68 loss: 69.5524\n",
      "Epoch: 69 loss: 68.8405\n",
      "Epoch: 70 loss: 68.8224\n",
      "Test_loss: 8.9265\n",
      "Epoch: 71 loss: 69.8387\n",
      "Epoch: 72 loss: 69.8722\n",
      "Epoch: 73 loss: 69.1745\n",
      "Epoch: 74 loss: 72.3771\n",
      "Epoch: 75 loss: 71.9271\n",
      "Epoch: 76 loss: 70.2356\n",
      "Epoch: 77 loss: 69.0316\n",
      "Epoch: 78 loss: 69.2504\n",
      "Epoch: 79 loss: 69.5311\n",
      "Epoch: 80 loss: 68.4384\n",
      "Test_loss: 6.4197\n",
      "Epoch: 81 loss: 69.9863\n",
      "Epoch: 82 loss: 71.3791\n",
      "Epoch: 83 loss: 70.1737\n",
      "Epoch: 84 loss: 69.2577\n",
      "Epoch: 85 loss: 67.9219\n",
      "Epoch: 86 loss: 69.9494\n",
      "Epoch: 87 loss: 63.9547\n",
      "Epoch: 88 loss: 67.8593\n",
      "Epoch: 89 loss: 67.8282\n",
      "Epoch: 90 loss: 66.9131\n",
      "Test_loss: 5.1907\n",
      "Epoch: 91 loss: 68.0300\n",
      "Epoch: 92 loss: 69.3432\n",
      "Epoch: 93 loss: 65.8947\n",
      "Epoch: 94 loss: 66.6173\n",
      "Epoch: 95 loss: 67.6185\n",
      "Epoch: 96 loss: 67.4131\n",
      "Epoch: 97 loss: 72.0954\n",
      "Epoch: 98 loss: 68.2872\n",
      "Epoch: 99 loss: 62.8469\n",
      "Epoch: 100 loss: 64.1986\n",
      "Test_loss: 3.4657\n"
     ]
    }
   ],
   "source": [
    "test_interval = 10\n",
    "num_epochs = 100\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2, y in zip(\n",
    "        x_0s_train,\n",
    "        x_1s_train,\n",
    "        x_2s_train,\n",
    "        laplacian_0s_train,\n",
    "        laplacian_1s_train,\n",
    "        laplacian_2s_train,\n",
    "        y_train,\n",
    "    ):\n",
    "        x_0, x_1, x_2, y = (\n",
    "            torch.tensor(x_0).float().to(device),\n",
    "            torch.tensor(x_1).float().to(device),\n",
    "            torch.tensor(x_2).float().to(device),\n",
    "            torch.tensor(y).float().to(device),\n",
    "        )\n",
    "        laplacian_0, laplacian_1, laplacian_2 = (\n",
    "            laplacian_0.float().to(device),\n",
    "            laplacian_1.float().to(device),\n",
    "            laplacian_2.float().to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2, y in zip(\n",
    "                x_0s_test,\n",
    "                x_1s_test,\n",
    "                x_2s_test,\n",
    "                laplacian_0s_test,\n",
    "                laplacian_1s_test,\n",
    "                laplacian_2s_test,\n",
    "                y_test,\n",
    "            ):\n",
    "                x_0, x_1, x_2, y = (\n",
    "                    torch.tensor(x_0).float().to(device),\n",
    "                    torch.tensor(x_1).float().to(device),\n",
    "                    torch.tensor(x_2).float().to(device),\n",
    "                    torch.tensor(y).float().to(device),\n",
    "                )\n",
    "                laplacian_0, laplacian_1, laplacian_2 = (\n",
    "                    laplacian_0.float().to(device),\n",
    "                    laplacian_1.float().to(device),\n",
    "                    laplacian_2.float().to(device),\n",
    "                )\n",
    "                y_hat = model(x_0, x_1, x_2, laplacian_0, laplacian_1, laplacian_2)\n",
    "                test_loss = loss_fn(y_hat, y)\n",
    "            print(f\"Test_loss: {test_loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
