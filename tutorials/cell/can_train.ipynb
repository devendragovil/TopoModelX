{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Convolutional Cell Complex Network (CCXN)\n",
    "\n",
    "We create and train a simplified version of the CCXN originally proposed in [Hajij et. al : Cell Complex Neural Networks (2020)](https://arxiv.org/pdf/2010.00743.pdf).\n",
    "\n",
    "### The Neural Network:\n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "1. A convolution from nodes to nodes using an adjacency message passing scheme (AMPS):\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow \\{z\\} \\rightarrow x}^{(0 \\rightarrow 1 \\rightarrow 0)} = M_{\\mathcal{L}_\\uparrow}^t(h_x^{t,(0)}, h_y^{t,(0)}, \\Theta^{t,(y \\rightarrow x)})$ \n",
    "\n",
    "游릲 $\\quad m_x^{(0 \\rightarrow 1 \\rightarrow 0)} = AGG_{y \\in \\mathcal{L}_\\uparrow(x)}(m_{y \\rightarrow \\{z\\} \\rightarrow x}^{0 \\rightarrow 1 \\rightarrow 0})$ \n",
    "\n",
    "游릴 $\\quad m_x^{(0)} = m_x^{(0 \\rightarrow 1 \\rightarrow 0)}$ \n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)} = U^{t}(h_x^{t,(0)}, m_x^{(0)})$\n",
    "\n",
    "2. A convolution from edges to faces using a cohomology message passing scheme:\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow x}^{(r' \\rightarrow r)} = M^t_{\\mathcal{C}}(h_{x}^{t,(r)}, h_y^{t,(r')}, x, y)$ \n",
    "\n",
    "游릲 $\\quad m_x^{(r' \\rightarrow r)}  = AGG_{y \\in \\mathcal{C}(x)} m_{y \\rightarrow x}^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릴 $\\quad m_x^{(r)} = m_x^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릱 $\\quad h_{x}^{t+1,(r)} = U^{t,(r)}(h_{x}^{t,(r)}, m_{x}^{(r)})$\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031).\n",
    "\n",
    "### The Task:\n",
    "\n",
    "We train this model to perform entire complex classification on [`MUTAG` from the TUDataset](https://paperswithcode.com/dataset/mutag). This dataset contains:\n",
    "- 188 samples of chemical compounds represented as graphs,\n",
    "- with 7 discrete node features.\n",
    "\n",
    "The task is to predict the mutagenicity of each compound on Salmonella typhimurium."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:06:36.009880829Z",
     "start_time": "2023-05-31T09:06:34.285257706Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from toponetx import CellComplex\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "from topomodelx.nn.cell.can_layer import CANLayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:13:53.006542411Z",
     "start_time": "2023-05-31T09:13:52.963074076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "We import a subset of MUTAG, a benchmark dataset for graph classification. \n",
    "\n",
    "We then lift each graph into our topological domain of choice, here: a cell complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0` and `x_1` on the nodes (0-cells) and edges (1-cells) for each complex: these will be the model's inputs,\n",
    "- a binary classification label `y` associated to the cell complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:13:55.279147916Z",
     "start_time": "2023-05-31T09:13:55.269057585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features on nodes for the 0th cell complex: torch.Size([17, 7]).\n",
      "Features on edges for the 0th cell complex: torch.Size([38, 4]).\n",
      "Label of 0th cell complex: 1.\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(\n",
    "    root=\"/tmp/MUTAG\", name=\"MUTAG\", use_edge_attr=True, use_node_attr=True\n",
    ")\n",
    "dataset = dataset[:20]\n",
    "cc_list = []\n",
    "x_0_list = []\n",
    "x_1_list = []\n",
    "y_list = []\n",
    "for graph in dataset:\n",
    "    cell_complex = CellComplex(to_networkx(graph))\n",
    "    cc_list.append(cell_complex)\n",
    "    x_0_list.append(graph.x)\n",
    "    x_1_list.append(graph.edge_attr)\n",
    "    y_list.append(int(graph.y))\n",
    "\n",
    "i_cc = 0\n",
    "print(f\"Features on nodes for the {i_cc}th cell complex: {x_0_list[i_cc].shape}.\")\n",
    "print(f\"Features on edges for the {i_cc}th cell complex: {x_1_list[i_cc].shape}.\")\n",
    "print(f\"Label of {i_cc}th cell complex: {y_list[i_cc]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 38])\n"
     ]
    }
   ],
   "source": [
    "for graph in dataset:\n",
    "    cell_complex = CellComplex(to_networkx(graph))\n",
    "    x = cell_complex.down_laplacian_matrix(rank=1)\n",
    "    try:\n",
    "        x = cell_complex.up_laplacian_matrix(rank=1)\n",
    "    except:\n",
    "        x = torch.zeros((x.shape[0], x.shape[0]))\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Implementing the CCXN architecture will require to perform message passing along neighborhood structures of the cell complexes.\n",
    "\n",
    "Thus, now we retrieve these neighborhood structures (i.e. their representative matrices) that we will use to send messages. \n",
    "\n",
    "For the CCXN, we need the adjacency matrix $A_{\\uparrow, 0}$ and the coboundary matrix $B_2^T$ of each cell complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:13:55.832585216Z",
     "start_time": "2023-05-31T09:13:55.815448708Z"
    }
   },
   "outputs": [],
   "source": [
    "lower_neighborhood_list = []\n",
    "upper_neighborhood_list = []\n",
    "\n",
    "for cell_complex in cc_list:\n",
    "    lower_neighborhood_t = cell_complex.down_laplacian_matrix(rank=1)\n",
    "    lower_neighborhood_t = torch.from_numpy(lower_neighborhood_t.todense()).to_sparse()\n",
    "    lower_neighborhood_list.append(lower_neighborhood_t)\n",
    "\n",
    "    try:\n",
    "        upper_neighborhood_t = cell_complex.up_laplacian_matrix(rank=1)\n",
    "        upper_neighborhood_t = torch.from_numpy(upper_neighborhood_t.todense()).to_sparse()\n",
    "    except:\n",
    "        upper_neighborhood_t = np.zeros((lower_neighborhood_t.shape[0], lower_neighborhood_t.shape[0]))\n",
    "        upper_neighborhood_t = torch.from_numpy(upper_neighborhood_t).to_sparse()\n",
    "\n",
    "    \n",
    "    upper_neighborhood_list.append(upper_neighborhood_t)\n",
    "\n",
    "i_cc = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CCXNLayer class, we create a neural network with stacked layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:13:56.672913561Z",
     "start_time": "2023-05-31T09:13:56.667986426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input features on nodes, edges and faces are: 7, 4 and 5.\n"
     ]
    }
   ],
   "source": [
    "in_channels_0 = x_0_list[0].shape[-1]\n",
    "in_channels_1 = x_1_list[0].shape[-1]\n",
    "in_channels_2 = 5\n",
    "print(\n",
    "    f\"The dimension of input features on nodes, edges and faces are: {in_channels_0}, {in_channels_1} and {in_channels_2}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:39.455212236Z",
     "start_time": "2023-05-31T09:19:39.452286461Z"
    }
   },
   "outputs": [],
   "source": [
    "class CAN(torch.nn.Module):\n",
    "    \"\"\"CAN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        num_classes,\n",
    "        n_layers=2,\n",
    "        att=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        layers.append(                \n",
    "            CANLayer(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    aggr_func=\"sum\",\n",
    "                    update_func=\"relu\"\n",
    "                )\n",
    "        )\n",
    "\n",
    "        for _ in range(n_layers-1):\n",
    "            layers.append(\n",
    "                CANLayer(\n",
    "                    in_channels=out_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    aggr_func=\"sum\",\n",
    "                    update_func=\"relu\"\n",
    "                )\n",
    "            )\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.lin_0 = torch.nn.Linear(out_channels, 1024)\n",
    "        self.lin_1 = torch.nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x, lower_neighborhood, upper_neighborhood):\n",
    "        \"\"\"Forward computation through layers, then linear layers, then avg pooling.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, lower_neighborhood, upper_neighborhood)\n",
    "            \n",
    "\n",
    "        # max pooling over all nodes in each graph\n",
    "        x = x.max(dim=0)[0]\n",
    "\n",
    "        # FF-NN\n",
    "        out = self.lin_1(torch.nn.functional.relu(self.lin_0(x)))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:40.411845803Z",
     "start_time": "2023-05-31T09:19:40.408861921Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CAN(in_channels_1, 32, num_classes=2, n_layers=1)\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:41.150933630Z",
     "start_time": "2023-05-31T09:19:41.146986990Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "x_1_train, x_1_test = train_test_split(x_1_list, test_size=test_size, shuffle=False)\n",
    "lower_neighborhood_train, lower_neighborhood_test = train_test_split(\n",
    "    lower_neighborhood_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "upper_neighborhood_train, upper_neighborhood_test = train_test_split(\n",
    "    upper_neighborhood_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(y_list, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the CCXN using low amount of epochs: we keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:42.918836083Z",
     "start_time": "2023-05-31T09:19:42.114801039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.7362 Train_acc: 0.2857\n",
      "Epoch: 2 loss: 0.6698 Train_acc: 0.5714\n",
      "Test_acc: 0.6667\n",
      "Epoch: 3 loss: 0.6654 Train_acc: 0.7143\n",
      "Epoch: 4 loss: 0.6479 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 5 loss: 0.6334 Train_acc: 0.7143\n",
      "Epoch: 6 loss: 0.6237 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 7 loss: 0.6160 Train_acc: 0.7143\n",
      "Epoch: 8 loss: 0.6085 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 9 loss: 0.6025 Train_acc: 0.7143\n",
      "Epoch: 10 loss: 0.5973 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 11 loss: 0.5931 Train_acc: 0.7143\n",
      "Epoch: 12 loss: 0.5889 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 13 loss: 0.5865 Train_acc: 0.7143\n",
      "Epoch: 14 loss: 0.5824 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 15 loss: 0.5802 Train_acc: 0.7143\n",
      "Epoch: 16 loss: 0.5777 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 17 loss: 0.5742 Train_acc: 0.7143\n",
      "Epoch: 18 loss: 0.5725 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 19 loss: 0.5703 Train_acc: 0.7143\n",
      "Epoch: 20 loss: 0.5685 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 21 loss: 0.5660 Train_acc: 0.7143\n",
      "Epoch: 22 loss: 0.5650 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 23 loss: 0.5624 Train_acc: 0.7143\n",
      "Epoch: 24 loss: 0.5624 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 25 loss: 0.5587 Train_acc: 0.7143\n",
      "Epoch: 26 loss: 0.5579 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 27 loss: 0.5561 Train_acc: 0.7143\n",
      "Epoch: 28 loss: 0.5550 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 29 loss: 0.5535 Train_acc: 0.7143\n",
      "Epoch: 30 loss: 0.5516 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 31 loss: 0.5504 Train_acc: 0.7143\n",
      "Epoch: 32 loss: 0.5483 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 33 loss: 0.5481 Train_acc: 0.7143\n",
      "Epoch: 34 loss: 0.5457 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 35 loss: 0.5436 Train_acc: 0.7143\n",
      "Epoch: 36 loss: 0.5424 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 37 loss: 0.5410 Train_acc: 0.7143\n",
      "Epoch: 38 loss: 0.5384 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 39 loss: 0.5398 Train_acc: 0.7143\n",
      "Epoch: 40 loss: 0.5352 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 41 loss: 0.5351 Train_acc: 0.7143\n",
      "Epoch: 42 loss: 0.5320 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 43 loss: 0.5322 Train_acc: 0.7143\n",
      "Epoch: 44 loss: 0.5305 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 45 loss: 0.5285 Train_acc: 0.7143\n",
      "Epoch: 46 loss: 0.5265 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 47 loss: 0.5247 Train_acc: 0.7143\n",
      "Epoch: 48 loss: 0.5215 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n",
      "Epoch: 49 loss: 0.5214 Train_acc: 0.7143\n",
      "Epoch: 50 loss: 0.5183 Train_acc: 0.7143\n",
      "Test_acc: 0.6667\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 50\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for x_1, lower_neighborhood, upper_neighborhood, y in zip(\n",
    "        x_1_train, lower_neighborhood_train, upper_neighborhood_train, y_train\n",
    "    ):\n",
    "        x_1, y = x_1.float().to(device), torch.tensor(y, dtype=torch.long).to(device)\n",
    "        lower_neighborhood, upper_neighborhood = lower_neighborhood.float().to(device), upper_neighborhood.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_1, lower_neighborhood, upper_neighborhood)\n",
    "\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_1, lower_neighborhood, upper_neighborhood, y in zip(\n",
    "                x_1_test, lower_neighborhood_test, upper_neighborhood_test, y_test\n",
    "            ):\n",
    "                x_1, y = x_1.float().to(device), torch.tensor(y, dtype=torch.long).to(device)\n",
    "                lower_neighborhood, upper_neighborhood = lower_neighborhood.float().to(device), upper_neighborhood.float().to(device)\n",
    "                y_hat = model(x_1, lower_neighborhood, upper_neighborhood)\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
