{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a hypergraph neural network using UniGCNII layers\n",
    "\n",
    "This tutorial consists of three main steps:\n",
    "1. Loading the CiCitationCora dataset and lifting it to the hypergraph domain.\n",
    "2. Defining a hypergraph neural network (HGNN) which utlilizes the UniGCNII layer, and\n",
    "3. Training the obtained neural network on the training data and evaluating it on test data.\n",
    "\n",
    "First, we import the neccessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from topomodelx.nn.hypergraph.unigcnii import UniGCNII\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPUs are available, we want to make use of them, otherwise the model is run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We are using the Cora co-citation dataset. Here, the nodes represent documents and the edges in the graph represent documents which are co-cited. It is possible to compute this graph from the citation network directly. However, this is computationally very expensive. Instead, we load the dataset directly as it is available to download.\n",
    "\n",
    "The task here is to classify each node and assign one of 7 possible classes to it. The dataset is a standard benchmark used in HGNN literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-03 14:49:01--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/features.pickle\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/features.pickle [following]\n",
      "--2023-11-03 14:49:01--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/features.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 404937 (395K) [application/octet-stream]\n",
      "Saving to: ‘features.pickle.1’\n",
      "\n",
      "features.pickle.1   100%[===================>] 395.45K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2023-11-03 14:49:02 (10.7 MB/s) - ‘features.pickle.1’ saved [404937/404937]\n",
      "\n",
      "--2023-11-03 14:49:02--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/hypergraph.pickle\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/hypergraph.pickle [following]\n",
      "--2023-11-03 14:49:02--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/hypergraph.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 101905 (100K) [application/octet-stream]\n",
      "Saving to: ‘hypergraph.pickle.1’\n",
      "\n",
      "hypergraph.pickle.1 100%[===================>]  99.52K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2023-11-03 14:49:02 (4.43 MB/s) - ‘hypergraph.pickle.1’ saved [101905/101905]\n",
      "\n",
      "--2023-11-03 14:49:03--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/labels.pickle\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/labels.pickle [following]\n",
      "--2023-11-03 14:49:03--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/labels.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5436 (5.3K) [application/octet-stream]\n",
      "Saving to: ‘labels.pickle.1’\n",
      "\n",
      "labels.pickle.1     100%[===================>]   5.31K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-11-03 14:49:03 (49.2 MB/s) - ‘labels.pickle.1’ saved [5436/5436]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/features.pickle\n",
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/hypergraph.pickle\n",
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/labels.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-03 14:49:04--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/splits/1.pickle\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/splits/1.pickle [following]\n",
      "--2023-11-03 14:49:04--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/splits/1.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51582 (50K) [application/octet-stream]\n",
      "Saving to: ‘1.pickle.1’\n",
      "\n",
      "1.pickle.1          100%[===================>]  50.37K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2023-11-03 14:49:04 (27.8 MB/s) - ‘1.pickle.1’ saved [51582/51582]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/splits/1.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_670387/2369537045.py:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  features = pickle.load(handle).todense()\n"
     ]
    }
   ],
   "source": [
    "with open(\"features.pickle\", \"rb\") as handle:\n",
    "    features = pickle.load(handle).todense()\n",
    "\n",
    "with open(\"hypergraph.pickle\", \"rb\") as handle:\n",
    "    hypergraph = pickle.load(handle)\n",
    "\n",
    "with open(\"labels.pickle\", \"rb\") as handle:\n",
    "    labels = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the input and output features to pytorch\n",
    "x_0 = sp.csr_matrix(np.array(features), dtype=np.float32)\n",
    "x_0 = torch.FloatTensor(np.array(x_0.todense()))\n",
    "x_0 = x_0.to(device)\n",
    "\n",
    "y = torch.LongTensor(np.array(labels))\n",
    "y = y.to(device)\n",
    "\n",
    "# construct the incidence matrix\n",
    "h = np.zeros((x_0.shape[0], len(hypergraph)))\n",
    "\n",
    "for num, nodes in enumerate(hypergraph.values()):\n",
    "    h[list(nodes), num] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add self-loops to the dataset i.e. for every node $v$, we add a hyper-edge only containing that specific node $e = \\{ v \\}$. This is the standard format expected by the GCNII layers and transform the matrix into a sparse pytorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_670387/2226475299.py:6: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  incidence = torch.Tensor(incidence).to_sparse_csr()\n"
     ]
    }
   ],
   "source": [
    "# add self loops\n",
    "h2 = np.eye(x_0.shape[0])\n",
    "incidence = np.hstack((h, h2))\n",
    "\n",
    "# transform to pytorch\n",
    "incidence = torch.Tensor(incidence).to_sparse_csr()\n",
    "incidence = incidence.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the predefine split in test and train data before we start constructing the HGNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train-test split given by the dataset\n",
    "with open(\"1.pickle\", \"rb\") as H:\n",
    "    splits = pickle.load(H)\n",
    "    train, test = splits[\"train\"], splits[\"test\"]\n",
    "\n",
    "train_idx = torch.LongTensor(train).to(device)\n",
    "test_idx = torch.LongTensor(test).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network that initializes the base model and sets up the readout operation.\n",
    "Different downstream tasks might require different pooling procedures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \"\"\" Network class that initializes the base model and readout layer.\n",
    "\n",
    "    Base model parameters:\n",
    "    ----------\n",
    "    Reqired:\n",
    "    in_channels : int\n",
    "        Dimension of the input features.\n",
    "    hidden_channels : int\n",
    "        Dimension of the hidden features.\n",
    "\n",
    "    Optitional:\n",
    "    **kwargs : dict\n",
    "        Additional arguments for the base model.\n",
    "    \n",
    "    Readout layer parameters:\n",
    "    ----------\n",
    "    out_channels : int\n",
    "        Dimension of the output features.\n",
    "    task_level : str\n",
    "        Level of the task. Either \"graph\" or \"node\".        \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            in_channels, \n",
    "            hidden_channels,\n",
    "            out_channels, \n",
    "            task_level=\"graph\",\n",
    "            **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the model\n",
    "        self.base_model = UniGCNII(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "        # Readout\n",
    "        self.linear = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.out_pool = True if task_level == \"graph\" else False\n",
    "        \n",
    "    def forward(self, x_0, incidence_1):\n",
    "        # Base model\n",
    "        x_0, x_1 = self.base_model(x_0, incidence_1)\n",
    "\n",
    "        # Pool over all nodes in the hypergraph \n",
    "        if self.out_pool is True:\n",
    "            x = torch.max(x_0, dim=0)[0]\n",
    "        else:\n",
    "            x = x_0\n",
    "\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model hyperparameters\n",
    "in_channels = x_0.shape[1]\n",
    "hidden_channels = 128\n",
    "n_layers=2\n",
    "mlp_num_layers=1\n",
    "input_drop=0.5\n",
    "\n",
    "# Readout hyperparameters\n",
    "out_channels = torch.unique(y).shape[0]\n",
    "task_level = \"graph\" if out_channels==1 else \"node\"\n",
    "\n",
    "\n",
    "model = Network(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=out_channels,\n",
    "    n_layers=n_layers,\n",
    "    input_drop=input_drop,\n",
    "    task_level=task_level,\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the neural network\n",
    "\n",
    "First, we specify the hyperparameters of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "test_interval = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can generate the corresponding model, optimizer, and loss function with corresponding sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Categorial cross-entropy loss\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Accuracy\n",
    "acc_fn = lambda y, y_hat: (y == y_hat).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to train the created model and evaluate the performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0               Train_loss: 1.8349, Train_acc: 0.5000               Test_loss: 1.8957, Test_acc: 0.2819\n",
      "Epoch: 5               Train_loss: 0.3446, Train_acc: 1.0000               Test_loss: 1.0406, Test_acc: 0.7099\n",
      "Epoch: 10               Train_loss: 0.0204, Train_acc: 1.0000               Test_loss: 1.2339, Test_acc: 0.7079\n",
      "Epoch: 15               Train_loss: 0.0401, Train_acc: 0.9929               Test_loss: 3.0919, Test_acc: 0.6223\n",
      "Epoch: 20               Train_loss: 0.0021, Train_acc: 1.0000               Test_loss: 3.9843, Test_acc: 0.6083\n",
      "Epoch: 25               Train_loss: 0.0006, Train_acc: 1.0000               Test_loss: 3.0639, Test_acc: 0.6748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    y_hat = model(x_0, incidence)\n",
    "    loss = loss_fn(y_hat[train_idx], y[train_idx])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    if epoch % test_interval == 0:\n",
    "        \n",
    "        model.eval()\n",
    "        y_hat = model(x_0, incidence)\n",
    "\n",
    "        train_loss = loss_fn(y_hat[train_idx], y[train_idx])\n",
    "        loss = loss_fn(y_hat[test_idx], y[test_idx])\n",
    "        print(f\"Epoch: {epoch} \\\n",
    "              Train_loss: {train_loss:.4f}, Train_acc: {acc_fn(y_hat[train_idx].argmax(1), y[train_idx]):.4f} \\\n",
    "              Test_loss: {loss:.4f}, Test_acc: {acc_fn(y_hat[test_idx].argmax(1), y[test_idx]):.4f}\",\n",
    "              flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('topox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6db82bc84658dc379dad2324c4569572404d1e9acb031924959aac21ff559da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
